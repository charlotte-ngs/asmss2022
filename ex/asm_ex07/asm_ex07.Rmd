---
title: Applied Statistical Methods - `r tools::toTitleCase(params$doctype)` 7
author: Peter von Rohr
date: 2022-04-06
output:
  bookdown::pdf_document2:
    toc: false
    number_sections: false
    keep_md: false
    keep_tex: false
header-includes:
 \usepackage{longtable}
 \usepackage{float}
params:
  doctype:
    label: 'Document Type'
    value: 'solution'
    choices: ['exercise', 'solution', 'notebook']
  isonline:
    label: 'Online (y/n)'
    value: TRUE
    choices: [TRUE, FALSE]
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r ex07-p01-init, echo=FALSE}
if (params$isonline){
  s_ex07p01_path <- "https://charlotte-ngs.github.io/asmss2022/data/asm_bw_mod_sel.csv" 
} else {
  s_ex07p01_path <- file.path(here::here(), "docs", "data", "asm_bw_mod_sel.csv")
}
```

## Problem 1: Model Selection
Given is a dataset with body weight as a response and different other variables and factors. The columns `Breed` and `BCS` (Body Condition Score) are taken as factors. All other columns are taken as predictor variables. The column `Animal` is not used in any model. Use model selection to find the relevant predictor variables and factors for the best linear fixed effect model. Use the estimated mean square error $C_p$ as a quality measure for a single linear model. The dataset to be analysed can be obtained from 

```{r, echo=FALSE}
cat(s_ex07p01_path, "\n")
```


### Your Tasks
* Run a forward selection for the given dataset to find the best model
* Do a backward elemination for the given dataset to find the best model
* Compare the two models whether they are identical with respect to the set of predictor variables and factors that they include.

<!-- your-solution-start
### Your Solution

Because, we need the residual standard deviation of the full model and backward elimination starts with the full model, we start with backward elimination

#### Start with Backward Elimination

* Start with the full model considering all variables and factors
* Eliminate the variable that increases the residual sum of squares the least and compute $C_p$ for resulting model
* Repeat above step until all variables and factors are elminiated
* Select the model with the smallest $C_p$ value

#### Forward Selection

* Forward selection starts with a minimal model containing only an intercept
* Add the variable that reduces the residual sum of squares the most and compute $C_p$ for that model
* Repeat step above until all variables are added
* Select from all the models the one with the smallest $C_p$ value

---  your-solution-end -->


<!-- master-solution-start -->

### Solution
Because, we need the residual standard deviation of the full model and backward elimination starts with the full model, we start with backward elimination

#### Backward Elimination

* Read the data and convert `Breed` and `BCS` to factors

```{r}
if (params$isonline){
  s_ex07p01_path <- "https://charlotte-ngs.github.io/asmss2022/data/asm_bw_mod_sel.csv" 
} else {
  s_ex07p01_path <- file.path(here::here(), "docs", "data", "asm_bw_mod_sel.csv")
}
tbl_ex07p01 <- readr::read_csv(file = s_ex07p01_path)
tbl_ex07p01$BCS <- as.factor(tbl_ex07p01$BCS)
tbl_ex07p01$Breed <- as.factor(tbl_ex07p01$Breed)
```

* Start with the full model considering all variables

```{r}
s_resp <- "BW"
vec_cols_to_ignore <- c("Animal")
vec_pred_full <- setdiff(colnames(tbl_ex07p01), c(s_resp, vec_cols_to_ignore))
fmlm_full <- as.formula(paste0(s_resp, " ~ ", 
                               paste0(vec_pred_full, collapse = " + "), 
                               collapse = ""))
lm_ex07p01_full <- lm(formula = fmlm_full, data = tbl_ex07p01)
smry_ex07p01_full <- summary(lm_ex07p01_full)
n_sd_full <- smry_ex07p01_full$sigma
n_ssqr_full <- crossprod(residuals(lm_ex07p01_full))
n_ssqr_full
```

* Eliminate the variable that increases the residual sum of squares the least and compute $C_p$ for resulting model

From the full model select one variable at the time, remove that variable, fit a reduced model and compute for that model the residual sum of squares. The model that increases the residual sum of squares the least, is selected and for that model the $C_p$ value is compute. 

```{r}
tbl_belim_res <- NULL
for (p in vec_pred_full){
  fm_update_cur <- as.formula(paste0(". ~ . - ", p, collapse = ""))
  lm_cur <- update(lm_ex07p01_full, fm_update_cur)
  vec_res <- residuals(lm_cur)
  tbl_cur <- tibble::tibble(Variable = p,
                            RSSQ = crossprod(vec_res))
  if (is.null(tbl_belim_res)){
    tbl_belim_res <- tbl_cur
  } else {
    tbl_belim_res <- dplyr::bind_rows(tbl_belim_res, tbl_cur)
  }
}
tbl_belim_res
```

From `tbl_belim_res`, we determine the variable which is excluded

```{r}
n_idx_var_exclude <- which(tbl_belim_res$RSSQ == min(tbl_belim_res$RSSQ))
s_var_exclude <- tbl_belim_res$Variable[n_idx_var_exclude]
s_var_exclude
```

The model after this first round of elimination corresponds to the model that results when taking away the variable `r s_var_exclude` from the full model.

```{r}
vec_pred_cur <- setdiff(vec_pred_full, s_var_exclude)
fm_cur <- as.formula(paste0(s_resp, " ~ ", 
                               paste0(vec_pred_cur, collapse = " + "), 
                               collapse = ""))
lm_cur <- lm(formula = fm_cur, data = tbl_ex07p01)
summary(lm_cur)
```

For the current model, we have to compute the $C_p$ value

```{r}
n_nr_obs <- nrow(tbl_ex07p01)
n_rssq <- crossprod(residuals(lm_cur))
# model size is the number of predictors plus the intercept
n_model_size <- length(vec_pred_cur) + 1 
n_cp_cur <- n_rssq / (n_sd_full^2) - n_nr_obs + 2 * n_model_size
n_cp_cur
```

Verify, according to https://search.r-project.org/CRAN/refmans/olsrr/html/ols_mallows_cp.html

```{r}
olsrr::ols_mallows_cp(lm_cur, lm_ex07p01_full)
```


* Repeat above step until all variables and factors are elminiated. The repetition could be done sequentially, but it is more efficient to do it in a loop. Inside of this loop, we have to perform several steps. For a better overview, we encapsulate these step in functions. The first function takes a model and returns a submodel with the one predictor variable or factor less such that the residual standard error increases the least. The second function is going to compute the $C_p$ value for a given sub-model and a full model. 

```{r}
get_subm_elim <- function(plm_cur_model){
  # minimal value for RSSQ
  n_rssq_min <- NULL
  lm_result_sub <- NULL
  # obtain the vector of predictor variables and factors
  vec_pred_cur <- attr(terms(plm_cur_model), "term.labels")
  # loop over vector of predictors and compute RSSQ for each sub-model
  for (p in vec_pred_cur){
    # remove p from predictors
    fm_cur_subm <- as.formula(paste0(". ~ . - ", p, collapse = ""))
    lm_cur_subm <- update(plm_cur_model, fm_cur_subm)
    vec_res_subm <- residuals(lm_cur_subm)
    n_rssq_subm <- crossprod(vec_res_subm)
    # check whether n_rssq_sub is minimal
    if (is.null(n_rssq_min)){
      n_rssq_min <- n_rssq_subm
      lm_result_sub <- lm_cur_subm
    } else {
      if (n_rssq_subm < n_rssq_min){
        n_rssq_min <- n_rssq_subm
        lm_result_sub <- lm_cur_subm
      }
    }
  }
  # return model with minimal rssq
  return(lm_result_sub)
}
```

The function `get_subm_elim()` can be verified by a call with the full model. Then the sub-model with `HEI` eliminated should result. 

```{r}
lm_ex07p01_first_subm <- get_subm_elim(plm_cur_model = lm_ex07p01_full)
lm_ex07p01_first_subm
```

The second function computes the $C_p$ value for the obtained sub-model.

```{r}
compute_cp_value <- function(pn_res_sd_full_model, pn_nr_obs, plm_cur_model){
  n_rssq <- crossprod(residuals(plm_cur_model))
  # model size is the number of predictors plus the intercept
  vec_pred_cur <- attr(terms(plm_cur_model), "term.labels")
  n_model_size <- length(vec_pred_cur) + 1 
  n_cp_cur <- n_rssq / (pn_res_sd_full_model^2) - pn_nr_obs + 2 * n_model_size
  return(n_cp_cur)
}
```

For the first submodel, we get

```{r}
compute_cp_value(pn_res_sd_full_model = n_sd_full, 
                 pn_nr_obs = nrow(tbl_ex07p01), 
                 plm_cur_model = lm_ex07p01_first_subm)
```

Now that we have the two functions ready, we can do the repetition of the elimination process of variables from a model. To make it a little bit easier, we start again with the full model.

```{r}
n_nr_obs <- nrow(tbl_ex07p01)
lm_current <- lm_ex07p01_full
n_sd_current <- summary(lm_current)$sigma
vec_pred_current <- attr(terms(lm_current), "term.labels")
# initialise a result dataframe
tbl_elim_result <- NULL
# loop as long as, there are variables in vec_pred_current
while (length(vec_pred_current) > 0){
  # get variables and C_p of current model
  tbl_elim_current <- tibble::tibble(`Current Model` = as.character(formula(lm_current))[3],
                                      Cp = compute_cp_value(pn_res_sd_full_model = n_sd_current,
                                                            pn_nr_obs = n_nr_obs, 
                                                            plm_cur_model = lm_current))
  # store variables and C_p value of current model in result
  if (is.null(tbl_elim_result)) {
    tbl_elim_result <- tbl_elim_current
  } else {
    tbl_elim_result <- dplyr::bind_rows(tbl_elim_result, tbl_elim_current)
  }
  # get new submodel
  lm_current <- get_subm_elim(plm_cur_model = lm_current)
  vec_pred_current <- attr(terms(lm_current), "term.labels")
}
tbl_elim_result
```

In the above shown result dataframe, the model which only fits an intercept is missing. Hence, we add that model to the results

```{r}
lm_inter <- lm(BW ~ 1, data = tbl_ex07p01)
tbl_elim_inter <- tibble::tibble(`Current Model` = as.character(formula(lm_inter))[3],
                                      Cp = compute_cp_value(pn_res_sd_full_model = n_sd_current,
                                                            pn_nr_obs = n_nr_obs, 
                                                            plm_cur_model = lm_inter))
tbl_elim_result <- dplyr::bind_rows(tbl_elim_result, tbl_elim_inter)
tbl_elim_result
```



* Select the model with the smallest $C_p$ value. The model with the smallest $C_p$ value 

```{r}
n_model_idx <- which(tbl_elim_result$Cp == min(tbl_elim_result$Cp))
tbl_elim_result[n_model_idx,]
```



<!-- master-solution-end -->


## Problem 2: Verification of Model Selection Results
Use the R-package `olsrr` to verify the results of Problem 1. Have a look at the documentation of `olsrr` at https://github.com/rsquaredacademy/olsrr. 

<!-- your-solution-start
### Your Solution

---  your-solution-end -->


<!-- master-solution-start -->

### Solution

<!-- master-solution-end -->


