---
title: Applied Statistical Methods - Notebook 7
author: Peter von Rohr
date: '2022-04-06'
output: html_notebook
params:
  doctype:
    label: Document Type
    value: solution
    choices:
    - exercise
    - solution
    - notebook
  isonline:
    label: Online (y/n)
    value: true
    choices:
    - true
    - false
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r ex07-p01-init, echo=FALSE}
if (params$isonline){
  s_ex07p01_path <- "https://charlotte-ngs.github.io/asmss2022/data/asm_bw_mod_sel.csv" 
} else {
  s_ex07p01_path <- file.path(here::here(), "docs", "data", "asm_bw_mod_sel.csv")
}
```

## Problem 1: Model Selection
Given is a dataset with body weight as a response and different other variables and factors. The columns `Breed` and `BCS` (Body Condition Score) are taken as factors. All other columns are taken as predictor variables. The column `Animal` is not used in any model. Use model selection to find the relevant predictor variables and factors for the best linear fixed effect model. Use the estimated mean square error $C_p$ as a quality measure for a single linear model. The dataset to be analysed can be obtained from 

```{r, echo=FALSE}
cat(s_ex07p01_path, "\n")
```


### Your Tasks
* Run a forward selection for the given dataset to find the best model
* Do a backward elemination for the given dataset to find the best model
* Compare the two models whether they are identical with respect to the set of predictor variables and factors that they include.

### Your Solution

Because, we need the residual standard deviation of the full model and backward elimination starts with the full model, we start with backward elimination

#### Start with Backward Elimination

* Start with the full model considering all variables and factors
* Eliminate the variable that increases the residual sum of squares the least and compute $C_p$ for resulting model
* Repeat above step until all variables and factors are elminiated
* Select the model with the smallest $C_p$ value

#### Forward Selection

* Forward selection starts with a minimal model containing only an intercept
* Add the variable that reduces the residual sum of squares the most and compute $C_p$ for that model
* Repeat step above until all variables are added
* Select from all the models the one with the smallest $C_p$ value





## Problem 2: Verification of Model Selection Results
Use the R-package `olsrr` to verify the results of Problem 1. Have a look at the documentation of `olsrr` at https://github.com/rsquaredacademy/olsrr. 

### Your Solution







```{r, echo=FALSE, results='asis'}
cat('\n---\n\n _Latest Changes: ', format(Sys.time(), '%Y-%m-%d %H:%M:%S'), ' (', Sys.info()['user'], ')_\n', sep = '')
```
 
