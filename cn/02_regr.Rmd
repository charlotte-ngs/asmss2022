# Linear Regression {#asm-regr}
```{r met-regr-reset, include=FALSE}
met$set_this_rmd_file(ps_this_rmd_file = ifelse(rstudioapi::isAvailable(), 
                                                 rstudioapi::getSourceEditorContext()$path, 
                                                 rprojroot::thisfile()))
```

## Introduction
This chapter is based on the book `r met$add("Searle1971")` and on the course notes `r met$add("Buhlmann2016")`. Regression analysis is used to assess relationships between a given variable and other measurements or observations on the same animal. The relationships between the variable and the other characteristics of the animal are estimated based on observed data. 


## Example
A classical example of a regression analysis in animal science is the relationship between bodyweight and breast circumference in cattle. This example has a practical application because the results of the regression analysis of body weight on breast circumference can be used for a measuring band. With such a measuring band the breast circumference of an animal is measured. On the back side of the band, the estimated body weight can directly be determined. 

At this point the question is how is it possible to determine the relationship between the values of breast circumference in centimeters and body weight in kilograms. The answer to this question can be given by a regression analysis. The most important pre-requisites for doing a regression analysis is to have a dataset. For our example, Table \@ref(tab:tab-reg-bw-bc) shows such a dataset which can be used for a regression analysis. 

```{r tab-reg-bw-bc, echo=FALSE, results='asis'}
tbl_reg <- tibble::tibble(Animal = c(1:10),
                          `Breast Circumference` = c(176, 177, 178, 179, 179, 180, 181, 182,183, 184),
                          `Body Weight` = c(471, 463, 481, 470, 496, 491, 518, 511, 510, 541))
n_nr_obs <- nrow(tbl_reg)
knitr::kable(tbl_reg,
             booktabs = TRUE,
             longtable = TRUE,
             caption = paste0("Breast Circumference and Body Weight for ", 
                              nrow(tbl_reg)," Animals", collapse = ""),
             escape = FALSE)
```

The dataset in Table \@ref(tab:tab-reg-bw-bc) contains measurements of body weight and breast circumference for $`r nrow(tbl_reg)`$ animals. Figure \@ref(fig:fig-reg-bw-bc) is a graphical representation of our example dataset. 

```{r fig-reg-bw-bc, echo=FALSE, fig.cap="Breast Circumference and Body Weight", fig.pos="!h", out.width="100%"}
library(ggplot2)
ggplot(tbl_reg, aes(x = `Breast Circumference`, y = `Body Weight`)) +
  geom_point(color = "blue") 
```

The diagram in Figure \@ref(fig:fig-reg-bw-bc) shows on the x-axis the breast circumference in cm and on the y-axis the body weight in kg. Each of the blue dots correspond to an observation of one animal in the dataset. A diagram like the one shown in Figure \@ref(fig:fig-reg-bw-bc) is also called a _dot plot_. From a first visual inspection of the dot plot for our dataset, we can see that there is a tendency that larger values of breast circumference of animals are related to heavier animals. The relationship is not deterministic that  means there are exceptions which do not follow the rule of this relationship. One example of an exception are animals 1 and 2. Animal 2 has a larger breast circumference value compared to animal 1,  but animal 2 has a lower body weight compared to animal 1. But despite such exceptions, we can still observe that on average there is a replationship between breast circumference and body weight. Furthermore, the apparent relationship between breast circumference and body weight seams to be the same for low and high values of breast circumference. Based on this last fact, we can say that the relationship between breast circumference and body weight is _linear_. 

```{r create-fig-non-linear, echo=FALSE, eval=FALSE}
# see https://rpubs.com/kaz_yos/ggplot2-stat-function and 
# https://ggplot2.tidyverse.org/reference/geom_function.html#examples
cn_odg_path <- file.path(here::here(), "cn", "odg")
library(ggplot2)
# quadratic function
p_quad <- ggplot() + xlim(-5,5)
fun.1 <- function(x) x^2 + x
p_quad <- p_quad + stat_function(fun = fun.1) 
ggsave(filename = file.path(cn_odg_path, "quadratic_function_plot.png"))
p_log <- ggplot() + xlim(0,10)
p_log <- p_log + stat_function(fun = function(x) log(x))
ggsave(filename = file.path(cn_odg_path, "log_function_plot.png"))
```

```{r fig-non-linear-rel, echo=FALSE, hook_convert_odg=TRUE, fig_path="odg", fig.cap="Examples of Non-Linear Functions", fig.pos="!h", out.width="100%"}
#rmdhelp::use_odg_graphic(ps_path = "odg/fig-non-linear-rel.odg")
knitr::include_graphics(path = "odg/fig-non-linear-rel.png")
```

Figure \@ref(fig:fig-non-linear-rel) shows two examples of non-linear functions. Both examples show that the relationship between the shown variables $x$ and $y$ is not the same over the shown range of values. Hence by inspecting the diagram of the two variables breast circumference and body weight of our example in Figure \@ref(fig:fig-reg-bw-bc), we can say that the relationship between the variables of our example dataset show a linear relationship.


## Regression Model
With the regression model we want to find a mathematical formulation to describe and to quantify the relationship between the two variables from  our example, breast circumference and body weight. One possibility to find this relationship is to take an animal with $x$ cm of breast circumference. Then the question is what would be the expected value for its body weight $y$ in kg. Under the assumption of a linear relationship between the variables from our example, the expected value $E(y)$ for the body weight $y$ can be written as 

\begin{equation}
E(y) = b_0 + b_1 * x
(\#eq:exbwregmodelregr)
\end{equation}

The above reasoning on how the variables are related is often referred to as _model building_. The model shown in \@ref(eq:exbwregmodelregr) is called a linear model, because the expected body weight ($E(y)$) is a linear function of the unknown _parameters_ $b_0$ and $b_1$. The number of possible models between two variables $x$ and $y$ is infinite. And therefore the process of model building is difficult and requires some experience. But in general, we can say that a simpler model with fewer unknown parameters is always preferrable over a more complex model as long as the simpler model is able to capture the most important aspects of a relationship between two variables. 


## Observations
For an animal with a breast circumference of $x$ cm, the body weight ($y$) will not exactly be $b_0 + b_1*x$. It has to be noted here that the values for $b_0$ and $b_1$ will be the same for all animals. The fact of the descrepency between the recorded body weights ($y$) and the output of the model is taken into account by writing $E(y)$ instead of $y$ in the model shown in equation \@ref(eq:exbwregmodelregr). For a given observed body weight $y_i$ of animal $i$ with a breast circumference of $x_i$, we can write 

\begin{equation}
E(y_i) = b_0 + b_1 * x_i
(\#eq:bwregmodelanimaliregr)
\end{equation}

where $E(y_i)$ is not the same as $y_i$. The difference $y_i - E(y_i)$ represents the difference between the observed body weight from its expected value $E(y_i)$ and is written as

\begin{equation}
e_i = y_i - E(y_i) = y_i - b_0 - b_1 * x_i
(\#eq:exbwregmodelresidualregr)
\end{equation}

Hence for the body weight $y_i$ of animal $i$, we can write

\begin{equation}
y_i = b_0 + b_1 * x_i + e_i
(\#eq:exbwregmodelobservedvalueregr)
\end{equation}

Equations \@ref(eq:bwregmodelanimaliregr), \@ref(eq:exbwregmodelresidualregr) and \@ref(eq:exbwregmodelobservedvalueregr) apply to all observations $y_1, y_2, \ldots, y_{`r n_nr_obs`}$, of our example dataset shown in Table \@ref(tab:tab-reg-bw-bc). The $e_i$ terms for all observations might take many different values. They include potential measurement errors or deficencies of the model itself. Due to the described properties of $e_i$'s, they are considered to be random variables and are usually called _random errors_ or _random residuals_.

To complete the description of our model in terms of equation \@ref(eq:exbwregmodelobservedvalueregr), further characteristics of the random errors ($e_i$) must be specified. These characteristics consist of 

* the _expected value_ $E(e_i)$ of $e_i$ and 
* the variance $var(e_i)$ of $e_i$. 

Useful specifications are that the expected value $E(e_i)$ is zero and all covariances between any pair of $e_i$ and $e_j$ with $i \ne j$ are also zero. Then the variance $var(e_i)$ is assumed to be a constant for all $i$ and is represented by the symbol $\sigma^2$. Summarizing all the proposed properties in a mathematical notation, we obtain

\begin{equation}
E(e_i) = 0
(\#eq:expvalueerrorregr)
\end{equation}

which is obtained from the definition of $e_i$ given in \@ref(eq:exbwregmodelresidualregr). The variance $var(e_i)$ 

\begin{equation}
var(e_i) = E\left[ e_i - E(e_i) \right]^2 = E(e_i^2) = \sigma^2
(\#eq:varerrorregr)
\end{equation}

and 

\begin{equation}
cov(e_i,e_j) = E\left[ e_i - E(e_i) \right]\left[ e_j - E(e_j) \right] = E(e_ie_j) = 0
(\#eq:coverrorregr)
\end{equation}

Equations \@ref(eq:bwregmodelanimaliregr) - \@ref(eq:coverrorregr) give a constitutional description of the linear model that we have designed so far for our example dataset. These properties form the basis for the procedure used to estimated the unknown parameters $b_0$ and $b_1$. 


## Parameter Estimation
There are several methods to estimate the unknown parameters $b_0$ and $b_1$ of the proposed linear model. The most frequently used method which is also implemented in the R-function `lm()` is called _least squares_. 

Least squares estimation is based on the idea of minimizing the sum of the squared deviations of the observations $y_i$ from their expected values. This sum can be written as 

\begin{equation}
\mathbf{e}^T\mathbf{e} = \sum_{i=1}^N e_i^2 = \sum_{i=1}^N \left[ y_i - E(e_i) \right]^2 = \sum_{i=1}^N \left[ y_i - b_0 - b_1*x_i \right]^2
(\#eq:sumsquareresidualregr)
\end{equation}

where $\mathbf{e}^T = \left[\begin{array}{cccc}e_1 & e_2 & \ldots & e_N \end{array}\right]$ is the transpose of the vector $\mathbf{e}$ of length $N$ containing all the $e_i$ values and $N$ stands for the number of observations. 

Although $b_0$ and $b_1$ are fixed (but unknown) values, we treat them for a moment like mathematical variables. The reason for this changed view is that we want to find the values for $b_0$ and $b_1$ that minimize the expression in \@ref(eq:sumsquareresidualregr). The resulting values from the minimization of \@ref(eq:sumsquareresidualregr) will be represented by the symbols $\hat{b}_0$ and $\hat{b}_1$ and they will be called the least squares estimators of $b_0$ and $b_1$. 

Minimization of \@ref(eq:sumsquareresidualregr) is done by taking partial derivatives with respect to both unknowns $b_0$ and $b_1$ and setting both derivatives to zero^[The verification of higher order derivative to confirm that the obtained extremal value is a minimum is not done here.]. This yields two equations from which solutions called $\hat{b}_0$ and $\hat{b}_1$ can be computed. 

\begin{align}
\frac{\partial\mathbf{e}^T\mathbf{e}}{\partial b_0} &= -2 \sum_{i=1}^N \left[y_i - b_0 - b_1x_i\right]  \notag \\
  &= -2\left[\sum_{i=1}^N y_i - Nb_0 - b_1\sum_{i=1}^N x_i\right]
(\#eq:derivssqresidualb0regr)
\end{align}

\begin{align}
\frac{\partial\mathbf{e}^T\mathbf{e}}{\partial b_1} &= -2 \sum_{i=1}^N x_i\left[y_i - b_0 - b_1x_i\right] \notag \\
  &= -2 \left[\sum_{i=1}^N x_iy_i - b_0 \sum_{i=1}^N x_i - b_1 \sum_{i=1}^N x_i^2 \right]
(\#eq:derivssqresidualb1regr)
\end{align}

Setting both expression in \@ref(eq:derivssqresidualb0regr) and \@ref(eq:derivssqresidualb1regr) to zero and writing them in terms of $\hat{b}_0$ and $\hat{b}_1$ gives 

\begin{equation}
N\hat{b}_0 + \hat{b}_1x. = y.
(\#eq:solderivssqresidualb0regr)
\end{equation}

and

\begin{equation}
\hat{b}_0x. + \hat{b}_1(x^2). = (xy).
(\#eq:solderivssqresidualb1regr)
\end{equation}

using the dot notation for the following sums $x. = \sum_{i=1}^N x_i$, $y. = \sum_{i=1}^N y_i$, $(x^2). = \sum_{i=1}^N x_i^2$ and $(xy). = \sum_{i=1}^N x_iy_i$. With the bar notation for the means, we can further write 

\begin{equation}
\bar{x}. = {x. \over N}
(\#eq:barxdotregr)
\end{equation}

and

\begin{equation}
\bar{y}. = {y. \over N}
(\#eq:barydotregr)
\end{equation}

The solutions in \@ref(eq:solderivssqresidualb0regr) and \@ref(eq:solderivssqresidualb1regr) can then be written as

\begin{equation}
\hat{b}_0 = \bar{y}. - \hat{b}_1\bar{x}.
(\#eq:solderivssqresidualb0regr)
\end{equation}

and

\begin{equation}
\hat{b}_1 = \frac{(xy). - N\bar{x}.\bar{y}.}{(x^2). - N\bar{x}.^2}
(\#eq:solderivssqresidualb1regr)
\end{equation}








 
